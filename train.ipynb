{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhgW_MGL4V6f"
      },
      "source": [
        "# TimesNet Training on ETT Datasets\n",
        "\n",
        "This notebook trains TimesNet on all 4 ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2) with different prediction horizons.\n",
        "\n",
        "**Datasets:**\n",
        "- ETTh1, ETTh2: Hourly data\n",
        "- ETTm1, ETTm2: 15-minute data\n",
        "\n",
        "**Configuration:**\n",
        "- Input length: 96 (fixed, as in paper)\n",
        "- Prediction horizons: {24, 48, 96, 192, 336, 720}\n",
        "- Total experiments: 4 datasets × 6 horizons = 24 models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmeZngpl4V6h"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ltruciosr-dev/timesnet-ett\n",
        "\n",
        "# Change to the cloned repository directory\n",
        "%cd timesnet-ett"
      ],
      "metadata": {
        "id": "AnPkHqZA4a6k",
        "outputId": "caa680b5-fb75-42cc-c36a-89b1f4b018f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'timesnet-ett'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 15 (delta 0), reused 15 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (15/15), 2.92 MiB | 6.22 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9OJZyIkK4V6h",
        "outputId": "a08d0bae-8fd0-425a-cc54-5cf8bc004365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('./src')\n",
        "\n",
        "from src.train import TimesNetTrainer\n",
        "from src.evaluate import evaluate_and_save_results, plot_training_curves\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pClMt56L4V6h"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fgSuegmr4V6h",
        "outputId": "5453675e-1e90-468b-c32d-4ed09f3afbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Configuration set\n",
            "  - Datasets: ['ETTh1', 'ETTh2', 'ETTm1', 'ETTm2']\n",
            "  - Input length: 96\n",
            "  - Prediction horizons: [24, 48, 96, 192, 336, 720]\n",
            "  - Total experiments: 24\n"
          ]
        }
      ],
      "source": [
        "# Base paths\n",
        "ROOT_PATH = './ETDataset/ETT-small/'\n",
        "CHECKPOINT_BASE = './checkpoints'\n",
        "RESULTS_DIR = './results'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Datasets\n",
        "DATASETS = ['ETTh1', 'ETTh2', 'ETTm1', 'ETTm2']\n",
        "\n",
        "# Fixed input length (as in paper)\n",
        "SEQ_LEN = 96\n",
        "\n",
        "# Prediction horizons\n",
        "PRED_LENS = [24, 48, 96, 192, 336, 720]\n",
        "\n",
        "# Model hyperparameters (from paper)\n",
        "MODEL_CONFIGS = {\n",
        "    'ETTh1': {'d_model': 16, 'd_ff': 32},\n",
        "    'ETTh2': {'d_model': 16, 'd_ff': 32},\n",
        "    'ETTm1': {'d_model': 32, 'd_ff': 64},\n",
        "    'ETTm2': {'d_model': 32, 'd_ff': 64},\n",
        "}\n",
        "\n",
        "# Training config\n",
        "TRAIN_CONFIG = {\n",
        "    'enc_in': 7,\n",
        "    'c_out': 7,\n",
        "    'top_k': 5,\n",
        "    'e_layers': 2,\n",
        "    'num_kernels': 6,\n",
        "    'dropout': 0.1,\n",
        "    'embed': 'fixed',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.0001,\n",
        "    'train_epochs': 10,\n",
        "    'patience': 3,\n",
        "    'lradj': 'type1',\n",
        "    'use_amp': False,\n",
        "    'num_workers': 0,\n",
        "}\n",
        "\n",
        "print(f\"✓ Configuration set\")\n",
        "print(f\"  - Datasets: {DATASETS}\")\n",
        "print(f\"  - Input length: {SEQ_LEN}\")\n",
        "print(f\"  - Prediction horizons: {PRED_LENS}\")\n",
        "print(f\"  - Total experiments: {len(DATASETS) * len(PRED_LENS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otYKSKVY4V6i"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nYcfecNm4V6i"
      },
      "outputs": [],
      "source": [
        "def train_single_model(dataset_name, pred_len):\n",
        "    \"\"\"\n",
        "    Train a single TimesNet model\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Dataset name (e.g., 'ETTh1')\n",
        "        pred_len: Prediction horizon\n",
        "\n",
        "    Returns:\n",
        "        dict: Training results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"Training: {dataset_name} | seq_len={SEQ_LEN} → pred_len={pred_len}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create config\n",
        "    config = {\n",
        "        'root_path': ROOT_PATH,\n",
        "        'data_path': f'{dataset_name}.csv',\n",
        "        'seq_len': SEQ_LEN,\n",
        "        'pred_len': pred_len,\n",
        "        'checkpoints': f'{CHECKPOINT_BASE}/{dataset_name}_{SEQ_LEN}_{pred_len}',\n",
        "        **TRAIN_CONFIG,\n",
        "        **MODEL_CONFIGS[dataset_name]\n",
        "    }\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    os.makedirs(config['checkpoints'], exist_ok=True)\n",
        "\n",
        "    # Train\n",
        "    trainer = TimesNetTrainer(config)\n",
        "    train_losses, val_losses = trainer.train()\n",
        "\n",
        "    # Test\n",
        "    test_results = trainer.test()\n",
        "\n",
        "    # Save training curves\n",
        "    curve_path = f'{RESULTS_DIR}/{dataset_name}_{SEQ_LEN}_{pred_len}_curves.png'\n",
        "    plot_training_curves(train_losses, val_losses, save_path=curve_path)\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        'dataset': dataset_name,\n",
        "        'seq_len': SEQ_LEN,\n",
        "        'pred_len': pred_len,\n",
        "        'd_model': config['d_model'],\n",
        "        'd_ff': config['d_ff'],\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'test_mse': test_results['mse'],\n",
        "        'test_mae': test_results['mae'],\n",
        "        'test_rmse': test_results['rmse'],\n",
        "        'final_epoch': len(train_losses),\n",
        "    }\n",
        "\n",
        "    print(f\"\\n✓ Completed: {dataset_name}_{SEQ_LEN}_{pred_len}\")\n",
        "    print(f\"  - Test MSE: {test_results['mse']:.6f}\")\n",
        "    print(f\"  - Test MAE: {test_results['mae']:.6f}\")\n",
        "    print(f\"  - Test RMSE: {test_results['rmse']:.6f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAIUi-py4V6i"
      },
      "source": [
        "## Train All Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASETS = ['ETTh1'] # ['ETTh1', 'ETTh2', 'ETTm1', 'ETTm2']"
      ],
      "metadata": {
        "id": "ydF9mVPA5iW5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEVL1a294V6i",
        "outputId": "35784038-c9f4-40ea-a979-8afda8ba1c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "# Experiment 1/6\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "Training: ETTh1 | seq_len=96 → pred_len=24\n",
            "======================================================================\n",
            "Using device: cuda\n",
            "Initializing data loaders...\n",
            "Train samples: 12075\n",
            "Val samples: 1719\n",
            "Test samples: 3461\n",
            "Initializing model...\n",
            "Model parameters: 598,431\n",
            "==================================================\n",
            "Starting training...\n",
            "==================================================\n",
            "\tIter: 100, Loss: 0.4570579\n",
            "\tIter: 200, Loss: 0.4372184\n",
            "\tIter: 300, Loss: 0.3997719\n",
            "Epoch: 1 | Time: 25.41s\n",
            "Train Loss: 0.4294014 | Val Loss: 0.3327421\n",
            "Validation loss decreased (inf --> 0.332742). Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\tIter: 100, Loss: 0.3306429\n",
            "\tIter: 200, Loss: 0.3145323\n",
            "\tIter: 300, Loss: 0.3504514\n"
          ]
        }
      ],
      "source": [
        "# Store all results\n",
        "all_results = []\n",
        "\n",
        "# Train all combinations\n",
        "total_experiments = len(DATASETS) * len(PRED_LENS)\n",
        "current_experiment = 0\n",
        "\n",
        "for dataset_name in DATASETS:\n",
        "    for pred_len in PRED_LENS:\n",
        "        current_experiment += 1\n",
        "\n",
        "        print(f\"\\n{'#'*70}\")\n",
        "        print(f\"# Experiment {current_experiment}/{total_experiments}\")\n",
        "        print(f\"{'#'*70}\")\n",
        "\n",
        "        try:\n",
        "            results = train_single_model(dataset_name, pred_len)\n",
        "            all_results.append(results)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error training {dataset_name}_{SEQ_LEN}_{pred_len}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ ALL TRAINING COMPLETED!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koruQ8qf4V6i"
      },
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo0xaPN54V6i"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrame for easy analysis\n",
        "results_df = pd.DataFrame([{\n",
        "    'dataset': r['dataset'],\n",
        "    'seq_len': r['seq_len'],\n",
        "    'pred_len': r['pred_len'],\n",
        "    'd_model': r['d_model'],\n",
        "    'd_ff': r['d_ff'],\n",
        "    'test_mse': r['test_mse'],\n",
        "    'test_mae': r['test_mae'],\n",
        "    'test_rmse': r['test_rmse'],\n",
        "    'final_epoch': r['final_epoch']\n",
        "} for r in all_results])\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = f'{RESULTS_DIR}/all_results.csv'\n",
        "results_df.to_csv(csv_path, index=False)\n",
        "print(f\"✓ Results saved to {csv_path}\")\n",
        "\n",
        "# Save detailed results (with training curves) to JSON\n",
        "json_path = f'{RESULTS_DIR}/all_results_detailed.json'\n",
        "with open(json_path, 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "print(f\"✓ Detailed results saved to {json_path}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Is0ZJ9C4V6i"
      },
      "source": [
        "## Results Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auev4rqz4V6i"
      },
      "source": [
        "### Results by Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VT_jCca4V6i"
      },
      "outputs": [],
      "source": [
        "# Group by dataset\n",
        "for dataset in DATASETS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{dataset} Results\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    dataset_results = results_df[results_df['dataset'] == dataset]\n",
        "    display(dataset_results[['pred_len', 'test_mse', 'test_mae', 'test_rmse', 'final_epoch']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riQOi-Nf4V6i"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMdk3L-e4V6i"
      },
      "outputs": [],
      "source": [
        "# Plot MSE vs Prediction Horizon for each dataset\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, dataset in enumerate(DATASETS):\n",
        "    ax = axes[idx]\n",
        "    dataset_results = results_df[results_df['dataset'] == dataset].sort_values('pred_len')\n",
        "\n",
        "    ax.plot(dataset_results['pred_len'], dataset_results['test_mse'],\n",
        "            marker='o', linewidth=2, markersize=8, label='MSE')\n",
        "    ax.plot(dataset_results['pred_len'], dataset_results['test_mae'],\n",
        "            marker='s', linewidth=2, markersize=8, label='MAE')\n",
        "\n",
        "    ax.set_xlabel('Prediction Horizon', fontsize=12)\n",
        "    ax.set_ylabel('Error', fontsize=12)\n",
        "    ax.set_title(f'{dataset} - Error vs Prediction Horizon', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/error_vs_horizon.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✓ Plot saved to {RESULTS_DIR}/error_vs_horizon.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESSrnHRd4V6i"
      },
      "outputs": [],
      "source": [
        "# Heatmap of MSE across datasets and horizons\n",
        "pivot_mse = results_df.pivot(index='dataset', columns='pred_len', values='test_mse')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(pivot_mse, annot=True, fmt='.4f', cmap='YlOrRd',\n",
        "            cbar_kws={'label': 'Test MSE'}, linewidths=0.5)\n",
        "plt.title('Test MSE: Dataset vs Prediction Horizon', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Prediction Horizon', fontsize=12)\n",
        "plt.ylabel('Dataset', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/mse_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✓ Heatmap saved to {RESULTS_DIR}/mse_heatmap.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGMa7-gv4V6i"
      },
      "outputs": [],
      "source": [
        "# Heatmap of MAE across datasets and horizons\n",
        "pivot_mae = results_df.pivot(index='dataset', columns='pred_len', values='test_mae')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(pivot_mae, annot=True, fmt='.4f', cmap='YlGnBu',\n",
        "            cbar_kws={'label': 'Test MAE'}, linewidths=0.5)\n",
        "plt.title('Test MAE: Dataset vs Prediction Horizon', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Prediction Horizon', fontsize=12)\n",
        "plt.ylabel('Dataset', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/mae_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✓ Heatmap saved to {RESULTS_DIR}/mae_heatmap.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9mAUm7M4V6i"
      },
      "source": [
        "### Statistical Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyeADhfL4V6i"
      },
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"=\"*70)\n",
        "print(\"STATISTICAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nOverall Statistics:\")\n",
        "print(results_df[['test_mse', 'test_mae', 'test_rmse']].describe())\n",
        "\n",
        "print(\"\\nBest Results (by MSE):\")\n",
        "best_mse = results_df.loc[results_df.groupby('dataset')['test_mse'].idxmin()]\n",
        "display(best_mse[['dataset', 'pred_len', 'test_mse', 'test_mae', 'test_rmse']])\n",
        "\n",
        "print(\"\\nBest Results (by MAE):\")\n",
        "best_mae = results_df.loc[results_df.groupby('dataset')['test_mae'].idxmin()]\n",
        "display(best_mae[['dataset', 'pred_len', 'test_mse', 'test_mae', 'test_rmse']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5fxSjSR4V6i"
      },
      "source": [
        "### Comparison with Paper Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u0NLdwv4V6i"
      },
      "outputs": [],
      "source": [
        "# Paper results (from TimesNet paper Table 1)\n",
        "paper_results = {\n",
        "    'ETTh1': {\n",
        "        96: {'mse': 0.384, 'mae': 0.402},\n",
        "        192: {'mse': 0.436, 'mae': 0.429},\n",
        "        336: {'mse': 0.491, 'mae': 0.469},\n",
        "        720: {'mse': 0.521, 'mae': 0.491},\n",
        "    },\n",
        "    'ETTm1': {\n",
        "        96: {'mse': 0.334, 'mae': 0.365},\n",
        "        192: {'mse': 0.374, 'mae': 0.385},\n",
        "        336: {'mse': 0.410, 'mae': 0.403},\n",
        "        720: {'mse': 0.478, 'mae': 0.437},\n",
        "    }\n",
        "}\n",
        "\n",
        "# Compare with our results\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARISON WITH PAPER RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for dataset in ['ETTh1', 'ETTm1']:\n",
        "    if dataset in paper_results:\n",
        "        print(f\"\\n{dataset}:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"{'Horizon':>10} {'Paper MSE':>12} {'Our MSE':>12} {'Diff':>10} {'Paper MAE':>12} {'Our MAE':>12} {'Diff':>10}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for horizon in [96, 192, 336, 720]:\n",
        "            if horizon in paper_results[dataset]:\n",
        "                paper = paper_results[dataset][horizon]\n",
        "                our = results_df[(results_df['dataset'] == dataset) & (results_df['pred_len'] == horizon)]\n",
        "\n",
        "                if not our.empty:\n",
        "                    our_mse = our['test_mse'].values[0]\n",
        "                    our_mae = our['test_mae'].values[0]\n",
        "\n",
        "                    mse_diff = ((our_mse - paper['mse']) / paper['mse']) * 100\n",
        "                    mae_diff = ((our_mae - paper['mae']) / paper['mae']) * 100\n",
        "\n",
        "                    print(f\"{horizon:>10} {paper['mse']:>12.4f} {our_mse:>12.4f} {mse_diff:>9.2f}% \"\n",
        "                          f\"{paper['mae']:>12.4f} {our_mae:>12.4f} {mae_diff:>9.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fH3-zI64V6i"
      },
      "source": [
        "## Export Results Table (LaTeX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ClTJaIi4V6i"
      },
      "outputs": [],
      "source": [
        "# Create LaTeX table\n",
        "latex_table = []\n",
        "latex_table.append(\"\\\\begin{table}[h]\")\n",
        "latex_table.append(\"\\\\centering\")\n",
        "latex_table.append(\"\\\\caption{TimesNet Results on ETT Datasets}\")\n",
        "latex_table.append(\"\\\\begin{tabular}{lcccc}\")\n",
        "latex_table.append(\"\\\\hline\")\n",
        "latex_table.append(\"Dataset & Horizon & MSE & MAE & RMSE \\\\\\\\\")\n",
        "latex_table.append(\"\\\\hline\")\n",
        "\n",
        "for dataset in DATASETS:\n",
        "    dataset_results = results_df[results_df['dataset'] == dataset].sort_values('pred_len')\n",
        "    for _, row in dataset_results.iterrows():\n",
        "        latex_table.append(f\"{row['dataset']} & {row['pred_len']} & \"\n",
        "                          f\"{row['test_mse']:.4f} & {row['test_mae']:.4f} & {row['test_rmse']:.4f} \\\\\\\\\")\n",
        "    latex_table.append(\"\\\\hline\")\n",
        "\n",
        "latex_table.append(\"\\\\end{tabular}\")\n",
        "latex_table.append(\"\\\\end{table}\")\n",
        "\n",
        "latex_str = \"\\n\".join(latex_table)\n",
        "\n",
        "# Save to file\n",
        "latex_path = f'{RESULTS_DIR}/results_table.tex'\n",
        "with open(latex_path, 'w') as f:\n",
        "    f.write(latex_str)\n",
        "\n",
        "print(f\"✓ LaTeX table saved to {latex_path}\")\n",
        "print(\"\\nLaTeX Table:\")\n",
        "print(latex_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlnSEBFr4V6i"
      },
      "source": [
        "## Summary\n",
        "\n",
        "✅ **Training Complete!**\n",
        "\n",
        "**Trained Models:**\n",
        "- 4 datasets (ETTh1, ETTh2, ETTm1, ETTm2)\n",
        "- 6 prediction horizons each (24, 48, 96, 192, 336, 720)\n",
        "- Total: 24 models\n",
        "\n",
        "**Output Files:**\n",
        "- `results/all_results.csv` - Summary table\n",
        "- `results/all_results_detailed.json` - Detailed results with training curves\n",
        "- `results/error_vs_horizon.png` - Error vs horizon plots\n",
        "- `results/mse_heatmap.png` - MSE heatmap\n",
        "- `results/mae_heatmap.png` - MAE heatmap\n",
        "- `results/results_table.tex` - LaTeX table\n",
        "- `results/{dataset}_{seq_len}_{pred_len}_curves.png` - Individual training curves\n",
        "- `checkpoints/{dataset}_{seq_len}_{pred_len}/checkpoint.pth` - Model checkpoints"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}